{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from LeNet5 import *\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on GPU...\n",
      "Forward pass successful\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device =='cuda':\n",
    "    print(\"Run on GPU...\")\n",
    "else:\n",
    "    print(\"Run on CPU...\")\n",
    "# Model Definition  \n",
    "net = LeNet5()\n",
    "net = net.to(device)\n",
    "\n",
    "# Test forward pass\n",
    "data = torch.randn(5,1,28,28)\n",
    "data = data.to(device)\n",
    "\n",
    "# Forward pass \"data\" through \"net\" to get output \"out\" \n",
    "out =  net(data) #Your code here\n",
    "\n",
    "# Check output shape\n",
    "assert(out.detach().cpu().numpy().shape == (5,10))\n",
    "print(\"Forward pass successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
